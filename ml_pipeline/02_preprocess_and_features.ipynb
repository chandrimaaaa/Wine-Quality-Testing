{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f7eef336",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyRegressor, DummyClassifier\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93844436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Part A: Load Cleaned Data\n",
    "file_path = \"data/processed/wine_quality_cleaned.csv\"\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(\"Cleaned data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    raise FileNotFoundError(f\"Could not find file at {file_path}. \"\n",
    "                            \"Please run 01_data_cleaning_eda.ipynb first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c92fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part B: Target Engineering\n",
    "# --------------------------------------------------------\n",
    "# Binary classification target: \"Good quality wine\" (quality >= 7)\n",
    "df[\"good_quality\"] = (df[\"quality\"] >= 7).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfadbbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "New features created:\n",
      "   quality  good_quality  acid_ratio  density_alcohol_interaction\n",
      "0        5             0   10.571413                      9.37932\n",
      "1        5             0    8.863626                      9.76864\n",
      "2        5             0   10.263144                      9.77060\n",
      "3        6             0   39.999857                      9.78040\n",
      "4        5             0   11.212104                      9.37932\n"
     ]
    }
   ],
   "source": [
    "# Part C: Feature Engineering\n",
    "\n",
    "# 1. Acid ratio (fixed/volatile) â†’ balance of acids\n",
    "df[\"acid_ratio\"] = df[\"fixed acidity\"] / (df[\"volatile acidity\"] + 1e-6)\n",
    "\n",
    "# 2. Interaction: density Ã— alcohol\n",
    "df[\"density_alcohol_interaction\"] = df[\"density\"] * df[\"alcohol\"]\n",
    "\n",
    "print(\"\\nNew features created:\")\n",
    "print(df[[\"quality\", \"good_quality\", \"acid_ratio\", \"density_alcohol_interaction\"]].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75cfc805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data splitting complete.\n",
      "Regression â†’ Train: (3724, 14), Test: (1596, 14)\n",
      "Classification â†’ Train: (3724, 14), Test: (1596, 14)\n"
     ]
    }
   ],
   "source": [
    "# Part D: Train/Test Split\n",
    "X = df.drop([\"quality\", \"good_quality\"], axis=1)\n",
    "y_reg = df[\"quality\"]       # regression target\n",
    "y_cls = df[\"good_quality\"]  # classification target\n",
    "\n",
    "# Regression split (70/30, random_state ensures reproducibility)\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Classification split (stratified due to imbalance)\n",
    "X_train_cls, X_test_cls, y_train_cls, y_test_cls = train_test_split(\n",
    "    X, y_cls, test_size=0.3, random_state=42, stratify=y_cls\n",
    ")\n",
    "\n",
    "print(\"\\nData splitting complete.\")\n",
    "print(f\"Regression â†’ Train: {X_train_reg.shape}, Test: {X_test_reg.shape}\")\n",
    "print(f\"Classification â†’ Train: {X_train_cls.shape}, Test: {X_test_cls.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12e949d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution (train vs test):\n",
      "Train:\n",
      " good_quality\n",
      "0    0.810419\n",
      "1    0.189581\n",
      "Name: proportion, dtype: float64\n",
      "Test:\n",
      " good_quality\n",
      "0    0.81015\n",
      "1    0.18985\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Check stratification\n",
    "print(\"\\nClass distribution (train vs test):\")\n",
    "print(\"Train:\\n\", y_train_cls.value_counts(normalize=True))\n",
    "print(\"Test:\\n\", y_test_cls.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73130a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Regression Baseline RMSE: 0.88 (â‰ˆ typical error in quality points)\n"
     ]
    }
   ],
   "source": [
    "# Part E: Baseline Models\n",
    "\n",
    "# 1. Regression baseline â†’ predict mean quality\n",
    "dummy_reg = DummyRegressor(strategy=\"mean\")\n",
    "dummy_reg.fit(X_train_reg, y_train_reg)\n",
    "y_pred_reg_dummy = dummy_reg.predict(X_test_reg)\n",
    "\n",
    "rmse_dummy = np.sqrt(mean_squared_error(y_test_reg, y_pred_reg_dummy))\n",
    "print(f\"\\nRegression Baseline RMSE: {rmse_dummy:.2f} \"\n",
    "      \"(â‰ˆ typical error in quality points)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b58afa54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Baseline Accuracy: 81.02%\n",
      "Classification Baseline F1-Score: 0.00\n",
      "Note: High accuracy, but fails to detect good wines (positive class).\n"
     ]
    }
   ],
   "source": [
    "# 2. Classification baseline â†’ always predict majority class\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf.fit(X_train_cls, y_train_cls)\n",
    "y_pred_cls_dummy = dummy_clf.predict(X_test_cls)\n",
    "\n",
    "acc_dummy = accuracy_score(y_test_cls, y_pred_cls_dummy)\n",
    "f1_dummy = f1_score(y_test_cls, y_pred_cls_dummy)\n",
    "print(f\"\\nClassification Baseline Accuracy: {acc_dummy:.2%}\")\n",
    "print(f\"Classification Baseline F1-Score: {f1_dummy:.2f}\")\n",
    "print(\"Note: High accuracy, but fails to detect good wines (positive class).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34480661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected 13 numeric features.\n",
      "Detected 1 categorical features.\n"
     ]
    }
   ],
   "source": [
    "# Part F: Preprocessing Pipeline\n",
    "# --------------------------------------------------------\n",
    "# Separate numeric & categorical features\n",
    "numeric_features = X_train_cls.select_dtypes(include=np.number).columns.tolist()\n",
    "categorical_features = X_train_cls.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "print(f\"\\nDetected {len(numeric_features)} numeric features.\")\n",
    "print(f\"Detected {len(categorical_features)} categorical features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85788277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformers\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "\n",
    "# ColumnTransformer â†’ applies right transformer to right feature type\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder=\"drop\"  # drop unused columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a69211df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preprocessing complete.\n",
      "Processed train shape: (3724, 15)\n",
      "Processed test shape: (1596, 15)\n"
     ]
    }
   ],
   "source": [
    "# Fit on train, transform train & test\n",
    "X_train_processed = preprocessor.fit_transform(X_train_cls)\n",
    "X_test_processed = preprocessor.transform(X_test_cls)\n",
    "\n",
    "print(f\"\\nPreprocessing complete.\")\n",
    "print(f\"Processed train shape: {X_train_processed.shape}\")\n",
    "print(f\"Processed test shape: {X_test_processed.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
